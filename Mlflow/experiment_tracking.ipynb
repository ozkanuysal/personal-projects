{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.14.0\n",
    "!pip install keras==2.5.0\n",
    "!pip install tensorflow-addons==0.22.0\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabtransformertf.models.fttransformer import FTTransformerEncoder, FTTransformer\n",
    "from tabtransformertf.utils.preprocessing import df_to_dataset\n",
    "\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.rcParams.update({'font.size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dset['data']\n",
    "y = dset['target']\n",
    "LABEL = dset['target_names'][0]\n",
    "\n",
    "NUMERIC_FEATURES = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Longitude', 'Latitude']\n",
    "\n",
    "data = pd.DataFrame(data, columns=dset['feature_names'])\n",
    "data[LABEL] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train_data, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train.loc[:, NUMERIC_FEATURES] = sc.fit_transform(X_train[NUMERIC_FEATURES])\n",
    "X_val.loc[:, NUMERIC_FEATURES] = sc.transform(X_val[NUMERIC_FEATURES])\n",
    "test_data.loc[:, NUMERIC_FEATURES] = sc.transform(test_data[NUMERIC_FEATURES])\n",
    "\n",
    "FEATURES = NUMERIC_FEATURES\n",
    "\n",
    "\n",
    "#plots\n",
    "sns.distplot(X_train[LABEL])\n",
    "sns.distplot(X_val[LABEL])\n",
    "sns.distplot(test_data[LABEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, max_depth=20)\n",
    "rf.fit(X_train[FEATURES], X_train[LABEL])\n",
    "\n",
    "rf_preds = rf.predict(test_data[FEATURES])\n",
    "rf_rms = mean_squared_error(test_data[LABEL], rf_preds, squared=False)\n",
    "print(rf_rms)\n",
    "\n",
    "\n",
    "\n",
    "# Catboost\n",
    "\n",
    "catb_train_dataset = cb.Pool(X_train[FEATURES], X_train[LABEL]) \n",
    "catb_val_dataset = cb.Pool(X_val[FEATURES], X_val[LABEL]) \n",
    "catb_test_dataset = cb.Pool(test_data[FEATURES], test_data[LABEL])\n",
    "\n",
    "tuned_catb = cb.CatBoostRegressor()\n",
    "tuned_catb.fit(catb_train_dataset, eval_set=catb_val_dataset, early_stopping_rounds=50)\n",
    "\n",
    "catb_preds = tuned_catb.predict(catb_test_dataset)\n",
    "catb_rms = mean_squared_error(test_data[LABEL], catb_preds, squared=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df_to_dataset(X_train[FEATURES + [LABEL]], LABEL, shuffle=True)\n",
    "val_dataset = df_to_dataset(X_val[FEATURES + [LABEL]], LABEL, shuffle=False)  \n",
    "test_dataset = df_to_dataset(test_data[FEATURES + [LABEL]], shuffle=False)\n",
    "\n",
    "ft_linear_encoder = FTTransformerEncoder(\n",
    "    numerical_features = NUMERIC_FEATURES,\n",
    "    categorical_features = [],\n",
    "    numerical_data = X_train[NUMERIC_FEATURES].values,\n",
    "    categorical_data =None, # No categorical data\n",
    "    y = None,\n",
    "    numerical_embedding_type='linear',\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True\n",
    ")\n",
    "\n",
    "# Pass th encoder to the model\n",
    "ft_linear_transformer = FTTransformer(\n",
    "    encoder=ft_linear_encoder,\n",
    "    out_dim=1,\n",
    "    out_activation=\"relu\",\n",
    ")\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "ft_linear_transformer.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = {\"output\": tf.keras.losses.MeanSquaredError(name='mse'), \"importances\": None},\n",
    "    metrics= {\"output\": [tf.keras.metrics.RootMeanSquaredError(name='rmse')], \"importances\": None},\n",
    ")\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_output_loss\", mode=\"min\", patience=16, restore_best_weights=True)\n",
    "callback_list = [early]\n",
    "\n",
    "ft_linear_history = ft_linear_transformer.fit(\n",
    "    train_dataset, \n",
    "    epochs=NUM_EPOCHS, \n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callback_list\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_periodic_encoder = FTTransformerEncoder(\n",
    "    numerical_features = NUMERIC_FEATURES,\n",
    "    categorical_features = [],\n",
    "    numerical_data = X_train[NUMERIC_FEATURES].values,\n",
    "    categorical_data = None,\n",
    "    y = None,\n",
    "    numerical_embedding_type='periodic',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True\n",
    ")\n",
    "\n",
    "# Pass th encoder to the model\n",
    "ft_periodic_transformer = FTTransformer(\n",
    "    encoder=ft_periodic_encoder,\n",
    "    out_dim=1,\n",
    "    out_activation=\"relu\",\n",
    ")\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "ft_periodic_transformer.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = {\"output\": tf.keras.losses.MeanSquaredError(name='mse'), \"importances\": None},\n",
    "    metrics= {\"output\": [tf.keras.metrics.RootMeanSquaredError(name='rmse')], \"importances\": None},\n",
    ")\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_output_loss\", mode=\"min\", patience=16, restore_best_weights=True)\n",
    "callback_list = [early]\n",
    "\n",
    "ft_periodic_history = ft_periodic_transformer.fit(\n",
    "    train_dataset, \n",
    "    epochs=NUM_EPOCHS, \n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_pleq_encoder = FTTransformerEncoder(\n",
    "    numerical_features = NUMERIC_FEATURES,\n",
    "    categorical_features = [],\n",
    "    numerical_data = X_train[NUMERIC_FEATURES].values,\n",
    "    categorical_data = None,\n",
    "    y = None,\n",
    "    numerical_embedding_type='ple',\n",
    "    numerical_bins=128,\n",
    "    embedding_dim=64,\n",
    "    depth=3,\n",
    "    heads=6,\n",
    "    attn_dropout=0.3,\n",
    "    ff_dropout=0.3,\n",
    "    explainable=True\n",
    ")\n",
    "\n",
    "# Pass the encoder to the model\n",
    "ft_pleq_transformer = FTTransformer(\n",
    "    encoder=ft_pleq_encoder,\n",
    "    out_dim=1,\n",
    "    out_activation=\"relu\",\n",
    ")\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "ft_pleq_transformer.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = {\"output\": tf.keras.losses.MeanSquaredError(name='mse'), \"importances\": None},\n",
    "    metrics= {\"output\": [tf.keras.metrics.RootMeanSquaredError(name='rmse')], \"importances\": None},\n",
    ")\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20, restore_best_weights=True)\n",
    "callback_list = [early]\n",
    "\n",
    "ft_pleq_history = ft_pleq_transformer.fit(\n",
    "    train_dataset, \n",
    "    epochs=NUM_EPOCHS, \n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callback_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ft_linear_history.history['val_loss'][:72], label='Linear Val Loss')\n",
    "plt.plot(ft_periodic_history.history['val_loss'][:100], label='Periodic Val Loss')\n",
    "plt.plot(ft_pleq_history.history['val_loss'][:100], label='PLE Quantile Val Loss')\n",
    "\n",
    "plt.title('Model Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test_preds = ft_linear_transformer.predict(test_dataset)\n",
    "linear_rms = mean_squared_error(test_data[LABEL], linear_test_preds['output'].ravel(), squared=False)\n",
    "\n",
    "periodic_test_preds = ft_periodic_transformer.predict(test_dataset)\n",
    "periodic_rms = mean_squared_error(test_data[LABEL], periodic_test_preds['output'].ravel()., squared=False)\n",
    "\n",
    "pleq_test_preds = ft_pleq_transformer.predict(test_dataset)\n",
    "pleq_rms = mean_squared_error(test_data[LABEL], pleq_test_preds['output'].ravel(), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
